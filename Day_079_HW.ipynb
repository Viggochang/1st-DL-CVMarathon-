{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "1. 請比較 SGD optimizer 不同的 momentum 及使用 nesterov 與否的表現"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# 本作業可以不需使用 GPU, 將 GPU 設定為 \"無\" (若想使用可自行開啟)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# 資料前處理 - X 標準化\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# 資料前處理 -Y 轉成 onehot\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(input_shape, output_units = 10, num_neurons = [512, 256, 128]):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units = n_units, activation = \"relu\", name=\"hidden_layer\"+str(i+1))(input_layer)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units = n_units, activation = \"relu\", name=\"hidden_layer\"+str(i+1))(x)\n",
    "    \n",
    "    out = keras. layers.Dense(units = output_units, activation = \"softmax\", name = \"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs = [input_layer], outputs = [out])\n",
    "    \"\"\"Code Here\n",
    "    建立你的神經網路\n",
    "    \"\"\"\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Code Here\n",
    "設定超參數\n",
    "\"\"\"\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256\n",
    "MOMENTUM = [0.95, 0.9, 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment eith momentum = 0.95\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 3072)]            0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 2.0641 - accuracy: 0.2576 - val_loss: 1.8943 - val_accuracy: 0.3283\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.8320 - accuracy: 0.3592 - val_loss: 1.7786 - val_accuracy: 0.3759\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.7469 - accuracy: 0.3862 - val_loss: 1.7040 - val_accuracy: 0.4015\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.6839 - accuracy: 0.4074 - val_loss: 1.6549 - val_accuracy: 0.4164\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.6424 - accuracy: 0.4215 - val_loss: 1.6189 - val_accuracy: 0.4276\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.6016 - accuracy: 0.4355 - val_loss: 1.6144 - val_accuracy: 0.4263\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.5705 - accuracy: 0.4469 - val_loss: 1.5841 - val_accuracy: 0.4407\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 1.5500 - accuracy: 0.4524 - val_loss: 1.5513 - val_accuracy: 0.4508\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.5194 - accuracy: 0.4654 - val_loss: 1.5217 - val_accuracy: 0.4573\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.4892 - accuracy: 0.4753 - val_loss: 1.5168 - val_accuracy: 0.4534\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.4672 - accuracy: 0.4832 - val_loss: 1.4910 - val_accuracy: 0.4668\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.4410 - accuracy: 0.4933 - val_loss: 1.4614 - val_accuracy: 0.4823\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.4246 - accuracy: 0.4991 - val_loss: 1.4490 - val_accuracy: 0.4852\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.4017 - accuracy: 0.5061 - val_loss: 1.4334 - val_accuracy: 0.4922\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 1.3903 - accuracy: 0.5124 - val_loss: 1.4235 - val_accuracy: 0.4944\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.3689 - accuracy: 0.5179 - val_loss: 1.4075 - val_accuracy: 0.5013\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 1.3504 - accuracy: 0.5229 - val_loss: 1.4213 - val_accuracy: 0.4907\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.3439 - accuracy: 0.5236 - val_loss: 1.4071 - val_accuracy: 0.5008\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.3220 - accuracy: 0.5343 - val_loss: 1.3979 - val_accuracy: 0.5056\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.3075 - accuracy: 0.5392 - val_loss: 1.3877 - val_accuracy: 0.5131\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 1.2922 - accuracy: 0.5435 - val_loss: 1.3739 - val_accuracy: 0.5107\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.2751 - accuracy: 0.5525 - val_loss: 1.3965 - val_accuracy: 0.5085\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.2682 - accuracy: 0.5531 - val_loss: 1.3862 - val_accuracy: 0.5074\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 1.2514 - accuracy: 0.5589 - val_loss: 1.3634 - val_accuracy: 0.5127\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.2377 - accuracy: 0.5644 - val_loss: 1.3993 - val_accuracy: 0.5072\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.2374 - accuracy: 0.5611 - val_loss: 1.3780 - val_accuracy: 0.5097\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 1.2121 - accuracy: 0.5715 - val_loss: 1.3624 - val_accuracy: 0.5170\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 1.2092 - accuracy: 0.5725 - val_loss: 1.3476 - val_accuracy: 0.5214\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 1.1907 - accuracy: 0.5792 - val_loss: 1.3470 - val_accuracy: 0.5237\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.1837 - accuracy: 0.5821 - val_loss: 1.3542 - val_accuracy: 0.5140\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.1714 - accuracy: 0.5861 - val_loss: 1.3501 - val_accuracy: 0.5276\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.1573 - accuracy: 0.5920 - val_loss: 1.3542 - val_accuracy: 0.5229\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.1471 - accuracy: 0.5955 - val_loss: 1.4074 - val_accuracy: 0.5048\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.1363 - accuracy: 0.6001 - val_loss: 1.3476 - val_accuracy: 0.5309\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.1184 - accuracy: 0.6067 - val_loss: 1.3109 - val_accuracy: 0.5375\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.1123 - accuracy: 0.6075 - val_loss: 1.3831 - val_accuracy: 0.5135\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.1182 - accuracy: 0.6053 - val_loss: 1.3321 - val_accuracy: 0.5277\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.0923 - accuracy: 0.6151 - val_loss: 1.3593 - val_accuracy: 0.5228\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.0806 - accuracy: 0.6195 - val_loss: 1.3292 - val_accuracy: 0.5305\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.0705 - accuracy: 0.6227 - val_loss: 1.3345 - val_accuracy: 0.5338\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.0600 - accuracy: 0.6267 - val_loss: 1.3114 - val_accuracy: 0.5384\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.0421 - accuracy: 0.6348 - val_loss: 1.3243 - val_accuracy: 0.5365\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.0381 - accuracy: 0.6350 - val_loss: 1.3196 - val_accuracy: 0.5354\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.0214 - accuracy: 0.6413 - val_loss: 1.3616 - val_accuracy: 0.5235\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.0168 - accuracy: 0.6405 - val_loss: 1.3186 - val_accuracy: 0.5411\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.0077 - accuracy: 0.6474 - val_loss: 1.3666 - val_accuracy: 0.5342\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 0.9943 - accuracy: 0.6503 - val_loss: 1.3297 - val_accuracy: 0.5394\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 0.9945 - accuracy: 0.6510 - val_loss: 1.3450 - val_accuracy: 0.5344\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 0.9703 - accuracy: 0.6594 - val_loss: 1.3206 - val_accuracy: 0.5417\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 2s 10ms/step - loss: 0.9537 - accuracy: 0.6644 - val_loss: 1.3685 - val_accuracy: 0.5297\n",
      "experiment eith momentum = 0.9\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 3072)]            0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "196/196 [==============================] - 2s 12ms/step - loss: 2.0907 - accuracy: 0.2553 - val_loss: 1.9481 - val_accuracy: 0.3174\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.8860 - accuracy: 0.3418 - val_loss: 1.8397 - val_accuracy: 0.3582\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.8060 - accuracy: 0.3698 - val_loss: 1.7827 - val_accuracy: 0.3785\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.7555 - accuracy: 0.3868 - val_loss: 1.7412 - val_accuracy: 0.3844\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.7143 - accuracy: 0.4020 - val_loss: 1.6991 - val_accuracy: 0.4020\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 1.6824 - accuracy: 0.4112 - val_loss: 1.6689 - val_accuracy: 0.4172\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 1.6533 - accuracy: 0.4240 - val_loss: 1.6526 - val_accuracy: 0.4234\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.6261 - accuracy: 0.4318 - val_loss: 1.6216 - val_accuracy: 0.4317\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.6017 - accuracy: 0.4409 - val_loss: 1.6052 - val_accuracy: 0.4348\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.5808 - accuracy: 0.4501 - val_loss: 1.5857 - val_accuracy: 0.4459\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.5634 - accuracy: 0.4529 - val_loss: 1.5703 - val_accuracy: 0.4459\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.5425 - accuracy: 0.4616 - val_loss: 1.5628 - val_accuracy: 0.4461\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.5285 - accuracy: 0.4652 - val_loss: 1.5502 - val_accuracy: 0.4477\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 1.5116 - accuracy: 0.4713 - val_loss: 1.5316 - val_accuracy: 0.4588\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.4964 - accuracy: 0.4771 - val_loss: 1.5251 - val_accuracy: 0.4622\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.4829 - accuracy: 0.4821 - val_loss: 1.5033 - val_accuracy: 0.4720\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.4670 - accuracy: 0.4862 - val_loss: 1.5098 - val_accuracy: 0.4720\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.4533 - accuracy: 0.4924 - val_loss: 1.4956 - val_accuracy: 0.4712\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.4450 - accuracy: 0.4946 - val_loss: 1.5016 - val_accuracy: 0.4663\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.4280 - accuracy: 0.5000 - val_loss: 1.4829 - val_accuracy: 0.4778\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 1.4201 - accuracy: 0.5039 - val_loss: 1.4596 - val_accuracy: 0.4799\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.4035 - accuracy: 0.5097 - val_loss: 1.4586 - val_accuracy: 0.4858\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.3967 - accuracy: 0.5110 - val_loss: 1.4467 - val_accuracy: 0.4876\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.3796 - accuracy: 0.5166 - val_loss: 1.4290 - val_accuracy: 0.4890\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.3717 - accuracy: 0.5188 - val_loss: 1.4481 - val_accuracy: 0.4900\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.3595 - accuracy: 0.5235 - val_loss: 1.4305 - val_accuracy: 0.4892\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.3544 - accuracy: 0.5235 - val_loss: 1.4256 - val_accuracy: 0.4954\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.3407 - accuracy: 0.5310 - val_loss: 1.4177 - val_accuracy: 0.5015\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.3273 - accuracy: 0.5334 - val_loss: 1.4077 - val_accuracy: 0.4987\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.3178 - accuracy: 0.5366 - val_loss: 1.4059 - val_accuracy: 0.4988\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.3065 - accuracy: 0.5400 - val_loss: 1.3970 - val_accuracy: 0.5040\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.2997 - accuracy: 0.5432 - val_loss: 1.4078 - val_accuracy: 0.4981\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.2932 - accuracy: 0.5456 - val_loss: 1.4129 - val_accuracy: 0.4968\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.2795 - accuracy: 0.5499 - val_loss: 1.3830 - val_accuracy: 0.5095\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.2702 - accuracy: 0.5531 - val_loss: 1.3787 - val_accuracy: 0.5046\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.2679 - accuracy: 0.5537 - val_loss: 1.3797 - val_accuracy: 0.5054\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.2569 - accuracy: 0.5572 - val_loss: 1.3924 - val_accuracy: 0.5034\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.2474 - accuracy: 0.5619 - val_loss: 1.3594 - val_accuracy: 0.5149\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.2374 - accuracy: 0.5656 - val_loss: 1.3550 - val_accuracy: 0.5189\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.2349 - accuracy: 0.5670 - val_loss: 1.3740 - val_accuracy: 0.5124\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.2185 - accuracy: 0.5710 - val_loss: 1.3570 - val_accuracy: 0.5152\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.2122 - accuracy: 0.5747 - val_loss: 1.3743 - val_accuracy: 0.5098\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.2093 - accuracy: 0.5767 - val_loss: 1.3533 - val_accuracy: 0.5138\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 1.1958 - accuracy: 0.5797 - val_loss: 1.3634 - val_accuracy: 0.5171\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 1.1870 - accuracy: 0.5840 - val_loss: 1.3586 - val_accuracy: 0.5185\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.1787 - accuracy: 0.5877 - val_loss: 1.3705 - val_accuracy: 0.5146\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.1693 - accuracy: 0.5888 - val_loss: 1.3626 - val_accuracy: 0.5173\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.1578 - accuracy: 0.5947 - val_loss: 1.3359 - val_accuracy: 0.5278\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.1525 - accuracy: 0.5955 - val_loss: 1.3507 - val_accuracy: 0.5198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.1490 - accuracy: 0.5961 - val_loss: 1.3361 - val_accuracy: 0.5255\n",
      "experiment eith momentum = 0.8\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 3072)]            0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 2.1554 - accuracy: 0.2227 - val_loss: 2.0364 - val_accuracy: 0.2964\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.9750 - accuracy: 0.3084 - val_loss: 1.9246 - val_accuracy: 0.3317\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.8910 - accuracy: 0.3394 - val_loss: 1.8637 - val_accuracy: 0.3483\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.8428 - accuracy: 0.3575 - val_loss: 1.8243 - val_accuracy: 0.3631\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.8066 - accuracy: 0.3678 - val_loss: 1.7944 - val_accuracy: 0.3737\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.7773 - accuracy: 0.3779 - val_loss: 1.7690 - val_accuracy: 0.3795\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.7522 - accuracy: 0.3876 - val_loss: 1.7431 - val_accuracy: 0.3897\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.7295 - accuracy: 0.3962 - val_loss: 1.7232 - val_accuracy: 0.3952\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.7099 - accuracy: 0.4037 - val_loss: 1.7071 - val_accuracy: 0.4045\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.6925 - accuracy: 0.4095 - val_loss: 1.6863 - val_accuracy: 0.4108\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.6758 - accuracy: 0.4157 - val_loss: 1.6739 - val_accuracy: 0.4188\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 1.6609 - accuracy: 0.4201 - val_loss: 1.6584 - val_accuracy: 0.4223\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.6462 - accuracy: 0.4238 - val_loss: 1.6436 - val_accuracy: 0.4259\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.6326 - accuracy: 0.4283 - val_loss: 1.6425 - val_accuracy: 0.4250\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.6204 - accuracy: 0.4348 - val_loss: 1.6229 - val_accuracy: 0.4331\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.6083 - accuracy: 0.4380 - val_loss: 1.6160 - val_accuracy: 0.4327\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.5969 - accuracy: 0.4419 - val_loss: 1.6068 - val_accuracy: 0.4373\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.5866 - accuracy: 0.4451 - val_loss: 1.5947 - val_accuracy: 0.4375\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.5757 - accuracy: 0.4505 - val_loss: 1.5843 - val_accuracy: 0.4456\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.5673 - accuracy: 0.4525 - val_loss: 1.5760 - val_accuracy: 0.4515\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.5561 - accuracy: 0.4564 - val_loss: 1.5679 - val_accuracy: 0.4514\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.5464 - accuracy: 0.4603 - val_loss: 1.5606 - val_accuracy: 0.4501\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 1.5389 - accuracy: 0.4628 - val_loss: 1.5523 - val_accuracy: 0.4556\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.5288 - accuracy: 0.4659 - val_loss: 1.5629 - val_accuracy: 0.4483\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.5228 - accuracy: 0.4667 - val_loss: 1.5370 - val_accuracy: 0.4598\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.5121 - accuracy: 0.4716 - val_loss: 1.5306 - val_accuracy: 0.4579\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.5036 - accuracy: 0.4747 - val_loss: 1.5308 - val_accuracy: 0.4595\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.4969 - accuracy: 0.4766 - val_loss: 1.5179 - val_accuracy: 0.4680\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.4882 - accuracy: 0.4798 - val_loss: 1.5135 - val_accuracy: 0.4671\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.4791 - accuracy: 0.4836 - val_loss: 1.5066 - val_accuracy: 0.4684\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.4728 - accuracy: 0.4856 - val_loss: 1.5049 - val_accuracy: 0.4721\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.4647 - accuracy: 0.4864 - val_loss: 1.5071 - val_accuracy: 0.4643\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.4592 - accuracy: 0.4905 - val_loss: 1.4920 - val_accuracy: 0.4746\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.4501 - accuracy: 0.4920 - val_loss: 1.4887 - val_accuracy: 0.4704\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.4424 - accuracy: 0.4951 - val_loss: 1.4881 - val_accuracy: 0.4756\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.4378 - accuracy: 0.4970 - val_loss: 1.4875 - val_accuracy: 0.4679\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.4286 - accuracy: 0.5010 - val_loss: 1.4696 - val_accuracy: 0.4776\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.4210 - accuracy: 0.5041 - val_loss: 1.4734 - val_accuracy: 0.4820\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.4151 - accuracy: 0.5046 - val_loss: 1.4578 - val_accuracy: 0.4844\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.4083 - accuracy: 0.5068 - val_loss: 1.4584 - val_accuracy: 0.4852\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.4019 - accuracy: 0.5086 - val_loss: 1.4502 - val_accuracy: 0.4857\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.3952 - accuracy: 0.5113 - val_loss: 1.4487 - val_accuracy: 0.4864\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.3895 - accuracy: 0.5133 - val_loss: 1.4409 - val_accuracy: 0.4896\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.3819 - accuracy: 0.5150 - val_loss: 1.4436 - val_accuracy: 0.4886\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.3765 - accuracy: 0.5178 - val_loss: 1.4400 - val_accuracy: 0.4894\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.3695 - accuracy: 0.5195 - val_loss: 1.4353 - val_accuracy: 0.4933\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.3642 - accuracy: 0.5213 - val_loss: 1.4239 - val_accuracy: 0.4970\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 1.3570 - accuracy: 0.5244 - val_loss: 1.4304 - val_accuracy: 0.4920\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 2s 10ms/step - loss: 1.3535 - accuracy: 0.5261 - val_loss: 1.4349 - val_accuracy: 0.4951\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.3464 - accuracy: 0.5281 - val_loss: 1.4203 - val_accuracy: 0.5013\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\"\"\"Code Here\n",
    "撰寫你的訓練流程並將結果用 dictionary 紀錄\n",
    "\"\"\"\n",
    "for m in MOMENTUM:\n",
    "    \n",
    "    keras.backend.clear_session()\n",
    "    print(f\"experiment eith momentum = {m}\")\n",
    "    model = build_mlp(x_train.shape[-1:])\n",
    "    model.summary()\n",
    "    \n",
    "    optimizer = keras.optimizers.SGD(lr = LEARNING_RATE, nesterov = False, momentum = m)\n",
    "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer = optimizer)\n",
    "    \n",
    "    model.fit(x_train, y_train,\n",
    "             epochs = EPOCHS, \n",
    "             batch_size = BATCH_SIZE, \n",
    "             validation_data = (x_test, y_test),\n",
    "             shuffle = True)\n",
    "    \n",
    "    #collect result\n",
    "    train_loss = model.history.history['loss']\n",
    "    train_acc = model.history.history['accuracy']\n",
    "    \n",
    "    test_loss = model.history.history['val_loss']\n",
    "    test_acc = model.history.history['val_accuracy']\n",
    "    \n",
    "    exp_name_tag = f\"exp-momentum-{m}\" \n",
    "    results[exp_name_tag] = {'train_loss':train_loss, \n",
    "                            'train_accuracy':train_acc, \n",
    "                            'test_loss':test_loss,\n",
    "                            'test_acc':test_acc}\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\"\"\"Code Here\n",
    "將結果繪出\n",
    "\"\"\"\n",
    "\n",
    "color_bar = [\"r\", \"g\", \"b\", \"y\", \"m\", \"k\"]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train_loss'])), results[cond]['train_loss'], '-', label = cond, color = color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['test_loss'])),results[cond]['test_loss'], '--', label = cond, color = color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train_'])), results[cond]['train_loss'], '-', label = cond, color = color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['test_loss'])),results[cond]['test_loss'], '--', label = cond, color = color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
